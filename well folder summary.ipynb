{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\adiarun\\Anaconda3\\lib\\site-packages\\lasio\\las.py:228: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  arr[arr == null] = np.nan\n",
      "D:\\adiarun\\Anaconda3\\lib\\site-packages\\lasio\\las.py:228: VisibleDeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  arr[arr == null] = np.nan\n",
      "Header section Well regexp=~W was not found.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lasio\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt \n",
    "def find_keyIndxWithStr(log,string):\n",
    "    found=False\n",
    "    indx=-999\n",
    "    for i,key in enumerate(log.keys()):\n",
    "        if string in key:\n",
    "            found=True\n",
    "            indx=i\n",
    "            break\n",
    "    \n",
    "    return found,indx\n",
    "def find_depth_indx(log):\n",
    "    found,indx=find_keyIndxWithStr(log,'DEPT')\n",
    "    if not found:\n",
    "        found,indx=find_keyIndxWithStr(log,'TVD')\n",
    "    if not found:\n",
    "        print('Depth collumn not found with existing tokens. Refine token in find_depth_indx function...')\n",
    "    return indx\n",
    "\n",
    "folder=r'D:\\Ameyem Office\\Projects\\Cairn\\W1\\LAS\\\\'\n",
    "cols=[]\n",
    "las=[]\n",
    "files=os.listdir(folder)[:]\n",
    "for f in files:\n",
    "    las.append(lasio.read(folder+f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dims': (2, 1), 'grid': [(0, 0), (1, 0)]}\n"
     ]
    }
   ],
   "source": [
    "# find_depth_indx(l),l[find_depth_indx(l)][0]\n",
    "class Struct:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)\n",
    "md={'dims': (2, 1), 'grid': [(0, 0), (1, 0)]}\n",
    "s = Struct(**md)\n",
    "s.dims\n",
    "spec = Struct(**md)\n",
    "print({str(key): md[key] for key in md})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkeys=[]\n",
    "descr=[]\n",
    "ranges=[]\n",
    "for l in las:\n",
    "#     print(l.keys())\n",
    "    lkeys.extend(l.keys())\n",
    "    descr.extend([l.curves[i]['descr'] for i in range(len(l.keys()))])\n",
    "    ranges.extend( [str(l[find_depth_indx(l)][0])+'-'+str(l[find_depth_indx(l)][-1])]*len(l.keys()))\n",
    "    \n",
    "\n",
    "# for k in well_dict:\n",
    "#     print(len(well_dict[k]))\n",
    "ranges=np.array(ranges)\n",
    "\n",
    "# [np.min(np.array(l[0])) for l in las]\n",
    "# for l in las:\n",
    "# print(np.min(l[0]),np.nanmax(l[0]))\n",
    "l[0]\n",
    "ulkeys,uindex, counts=np.unique(lkeys,return_index=True,return_counts=True)\n",
    "udescr=np.array(descr)[uindex]\n",
    "\n",
    "uranges=[]\n",
    "for uk in ulkeys:\n",
    "    indexs=np.where(np.array(lkeys)==uk)\n",
    "    uranges.append(' | '.join(np.sort(ranges[indexs])))\n",
    "uranges\n",
    "\n",
    "keysdf=pd.DataFrame({'Log name':ulkeys,'Description':udescr,'No. of Files having':counts,'Ranges':uranges})\n",
    "keysdf.to_csv(folder+'../key summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "number_files=len(las)\n",
    "n_of_logs=len(lkeys)-len(las) # all logs minus depth arrays\n",
    "\n",
    "ulkeys, counts = np.unique(lkeys, return_counts=True)\n",
    "# lkeys\n",
    "\n",
    "well_dict={0:['number of files','number of logs','File name'],\n",
    "1:[number_files,n_of_logs,'Number of logs'],\n",
    "2:['','','Depth min'],\n",
    "3:['','','Depth max']}\n",
    "\n",
    "well_dict[0].extend(files)\n",
    "well_dict[1].extend([len(l.keys())-1 for l in las])\n",
    "well_dict[2].extend([l[find_depth_indx(l)][0] for l in las])\n",
    "well_dict[3].extend([l[find_depth_indx(l)][-1] for l in las])\n",
    "welldf=pd.DataFrame(well_dict)\n",
    "welldf.to_csv(folder+'../well summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LWDRM 1HZ River Depth\n",
      "Equivalent Circulating Density\n",
      "ARC Annular Pressure\n",
      "ARC Annular Temperature\n"
     ]
    }
   ],
   "source": [
    "l.curves[3]['descr']\n",
    "lks=l.keys()\n",
    "for i,lk in enumerate(lks):\n",
    "[l.curves[i]['descr'] for i in range(len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['A10H' '4']\n",
      " ['A16H' '9']\n",
      " ['A16L' '3']\n",
      " ['A22H' '9']\n",
      " ['A22L' '3']\n",
      " ['A28H' '9']\n",
      " ['A28L' '3']\n",
      " ['A34H' '9']\n",
      " ['A34L' '3']\n",
      " ['A40H' '5']\n",
      " ['A40L' '3']\n",
      " ['APRS_ARC' '7']\n",
      " ['ATMP' '7']\n",
      " ['BIT' '5']\n",
      " ['CAL' '7']\n",
      " ['CALX' '1']\n",
      " ['CALXQH' '3']\n",
      " ['CHT' '4']\n",
      " ['CNCF' '5']\n",
      " ['CNCFLS' '5']\n",
      " ['CNCFLSQH' '5']\n",
      " ['CNCFQH' '5']\n",
      " ['CNCFSS' '5']\n",
      " ['CNCFSSQH' '5']\n",
      " ['DATE' '3']\n",
      " ['DCAV' '4']\n",
      " ['DCHO' '2']\n",
      " ['DCVE' '2']\n",
      " ['DEPT' '18']\n",
      " ['DRHB' '4']\n",
      " ['DRHO' '2']\n",
      " ['DT24' '3']\n",
      " ['DTC' '3']\n",
      " ['DTRP' '4']\n",
      " ['DTSD' '3']\n",
      " ['DTST' '3']\n",
      " ['DTXX' '3']\n",
      " ['ECDU' '3']\n",
      " ['ECD_ARC' '7']\n",
      " ['GR' '5']\n",
      " ['GRQH' '5']\n",
      " ['GRSL' '5']\n",
      " ['GR_ARC' '5']\n",
      " ['GR_IMP' '2']\n",
      " ['HORD' '4']\n",
      " ['K' '5']\n",
      " ['KTH' '5']\n",
      " ['M1R1' '3']\n",
      " ['M1R2' '3']\n",
      " ['M1R3' '3']\n",
      " ['M1R6' '3']\n",
      " ['M1R9' '3']\n",
      " ['M1RX' '3']\n",
      " ['M2R1' '3']\n",
      " ['M2R2' '3']\n",
      " ['M2R3' '3']\n",
      " ['M2R6' '3']\n",
      " ['M2R9' '3']\n",
      " ['M2RX' '3']\n",
      " ['MBVI' '2']\n",
      " ['MCBW' '2']\n",
      " ['MPHE' '2']\n",
      " ['MPHS' '2']\n",
      " ['MPRM' '2']\n",
      " ['P10H' '2']\n",
      " ['P16H' '7']\n",
      " ['P16L' '3']\n",
      " ['P22H' '7']\n",
      " ['P22L' '3']\n",
      " ['P28H' '7']\n",
      " ['P28L' '3']\n",
      " ['P34H' '7']\n",
      " ['P34L' '3']\n",
      " ['P40H' '5']\n",
      " ['P40L' '3']\n",
      " ['PE' '5']\n",
      " ['PEQH' '5']\n",
      " ['POIS' '3']\n",
      " ['PRSA_UPR' '3']\n",
      " ['RESH' '2']\n",
      " ['RESV' '2']\n",
      " ['RHOB' '2']\n",
      " ['RM_DEPTH' '3']\n",
      " ['ROBB' '4']\n",
      " ['ROP5_RM' '7']\n",
      " ['RPM_ADN' '2']\n",
      " ['RTHK' '5']\n",
      " ['RTHU' '5']\n",
      " ['RUK' '5']\n",
      " ['SPD' '5']\n",
      " ['TAB_ARC_RES' '3']\n",
      " ['TAB_IMP_GR' '2']\n",
      " ['TEN' '4']\n",
      " ['TH' '5']\n",
      " ['TICK_ARC_GR' '1']\n",
      " ['TICK_ARC_RES' '1']\n",
      " ['TIME' '3']\n",
      " ['TMPU_ANN' '3']\n",
      " ['TNPH' '4']\n",
      " ['TTC' '3']\n",
      " ['TTEN' '5']\n",
      " ['TTS' '3']\n",
      " ['TVDE' '3']\n",
      " ['U' '5']\n",
      " ['VERD' '4']\n",
      " ['VPVS' '3']\n",
      " ['ZCOR' '5']\n",
      " ['ZCORQH' '5']\n",
      " ['ZDNC' '5']\n",
      " ['ZDNCQH' '5']]\n"
     ]
    }
   ],
   "source": [
    "# ulkeys=np.unique(lkeys)\n",
    "ulkeys, counts = np.unique(lkeys, return_counts=True)\n",
    "ulkeys, counts\n",
    "print (np.asarray((ulkeys, counts)).T)\n",
    "# def merge_log(depthArr1,logArr1,depthArr2,logArr2):\n",
    "# for  \n",
    "# def find_depthrangesEachlog(ulkeys,las):\n",
    "#     logname=[]\n",
    "#     minmaxs=[]\n",
    "#     for l in las:\n",
    "#         minmaxs.append(min(l[0]),max(l[0]))\n",
    "# minmaxs   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
